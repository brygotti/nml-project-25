{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9934ebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(\n",
      "/home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/misenta/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac15ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            label  start_time  end_time       date  \\\n",
      "patient  session   segment                                           \n",
      "pqejgcff s001_t000 0            1         0.0      12.0 2003-01-01   \n",
      "                   1            1        12.0      24.0 2003-01-01   \n",
      "                   2            1        24.0      36.0 2003-01-01   \n",
      "                   3            1        36.0      48.0 2003-01-01   \n",
      "                   4            1        48.0      60.0 2003-01-01   \n",
      "\n",
      "                            sampling_rate                        signals_path  \n",
      "patient  session   segment                                                     \n",
      "pqejgcff s001_t000 0                  250  signals/pqejgcff_s001_t000.parquet  \n",
      "                   1                  250  signals/pqejgcff_s001_t000.parquet  \n",
      "                   2                  250  signals/pqejgcff_s001_t000.parquet  \n",
      "                   3                  250  signals/pqejgcff_s001_t000.parquet  \n",
      "                   4                  250  signals/pqejgcff_s001_t000.parquet  \n",
      "       to  distance\n",
      "from               \n",
      "FP1   FP1  0.000000\n",
      "FP1   FP2  0.618000\n",
      "FP1    F3  0.618969\n",
      "FP1    F4  1.030322\n",
      "FP1    C3  1.250226\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"../data/train/segments.parquet\")\n",
    "test_df = pd.read_parquet(\"../data/test/segments.parquet\")\n",
    "distances_df = pd.read_csv(\"../data/distances_3d.csv\", index_col=0)\n",
    "\n",
    "print(train_df.head())\n",
    "print(distances_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45df652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to get a square matrix\n",
    "distances_df_square = distances_df.pivot_table(index='from', columns='to', values='distance')\n",
    "distances_df_square = distances_df_square.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7551e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# Construction d’un graphe d’adjacence basé sur les distances\n",
    "def build_adjacency_matrix(distances_df, threshold=0.1):\n",
    "    mat = distances_df.values\n",
    "    adj = (mat < threshold).astype(int)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "    return adj\n",
    "\n",
    "adj_matrix = build_adjacency_matrix(distances_df_square, threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf31245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EEGGraphDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, adj_matrix, transform=None):\n",
    "        self.df = df.reset_index()\n",
    "        self.root_dir = root_dir\n",
    "        self.adj_matrix = torch.tensor(adj_matrix, dtype=torch.long)\n",
    "        self.edge_index = torch.nonzero(self.adj_matrix).t().contiguous()\n",
    "        self.transform = transform\n",
    "\n",
    "        # ⚡ Préchargement\n",
    "        self.signal_cache = {}\n",
    "        for path in self.df['signals_path'].unique():\n",
    "            full_path = os.path.join(root_dir, path)\n",
    "            self.signal_cache[path] = pd.read_parquet(full_path).T  # (n_channels, time)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        segment = self.signal_cache[row['signals_path']]\n",
    "        start = int(row['start_time'] * row['sampling_rate'])\n",
    "        end = int(row['end_time'] * row['sampling_rate'])\n",
    "\n",
    "        x = torch.tensor(segment.iloc[:, start:end].mean(axis=1).values, dtype=torch.float).unsqueeze(1)\n",
    "        y = torch.tensor(row['label'], dtype=torch.long)\n",
    "\n",
    "        data = Data(x=x, edge_index=self.edge_index, y=y)\n",
    "        return self.transform(data) if self.transform else data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1eeea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGGraphDataset(train_df, \"../data/train\", adj_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27143b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[19, 1], edge_index=[2, 96], y=1)\n",
      "torch.Size([19, 1]) torch.Size([2, 96]) tensor(1)\n",
      "Sample EEG segment:\n",
      "19 nodes (electrodes) with 1 features\n",
      "96 edges\n",
      "Label: 1 (0: healthy, 1: unhealthy)\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)\n",
    "print(sample.x.shape, sample.edge_index.shape, sample.y)\n",
    "\n",
    "\n",
    "print(\"Sample EEG segment:\")\n",
    "print(f\"{sample.x.shape[0]} nodes (electrodes) with {sample.x.shape[1]} features\")\n",
    "print(f\"{sample.edge_index.shape[1]} edges\")\n",
    "print(f\"Label: {sample.y.item()} (0: healthy, 1: unhealthy)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff6874",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aee4ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_split = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "val_split = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_split, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f538a5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class NeuroGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, edge_index, batch_index = batch.x, batch.edge_index, batch.batch\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch_index)\n",
    "        return self.lin(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c1a30",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a96156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 165.8006 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 02 | Loss: 156.9076 | Val Acc: 0.8045 | F1: 0.0379\n",
      "Epoch 03 | Loss: 156.9684 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 04 | Loss: 156.5931 | Val Acc: 0.8045 | F1: 0.0305\n",
      "Epoch 05 | Loss: 156.3801 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 06 | Loss: 155.8330 | Val Acc: 0.8034 | F1: 0.0377\n",
      "Epoch 07 | Loss: 155.2158 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 08 | Loss: 154.5912 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 09 | Loss: 154.1378 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 10 | Loss: 153.8465 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 11 | Loss: 154.0876 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 12 | Loss: 153.9364 | Val Acc: 0.8045 | F1: 0.0342\n",
      "Epoch 13 | Loss: 153.7105 | Val Acc: 0.8026 | F1: 0.0000\n",
      "Epoch 14 | Loss: 155.2776 | Val Acc: 0.8026 | F1: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     26\u001b[0m         pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/data/data.py:362\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/data/data.py:342\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 342\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/data/storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/data/storage.py:897\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/NML-PROJECT/lib/python3.10/site-packages/torch_geometric/data/data.py:363\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuroGNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            val_preds.append(pred.cpu())\n",
    "            val_labels.append(data.y.cpu())\n",
    "\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "\n",
    "    acc = accuracy_score(val_labels, val_preds)\n",
    "    f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {total_loss:.4f} | Val Acc: {acc:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dae011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NML-PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
